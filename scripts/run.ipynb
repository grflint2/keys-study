{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for es with method: normal\n",
      "models/cc.es.300.bin\n",
      "Finished loading model for es with method: normal\n",
      "Loading model for de with method: normal\n",
      "models/cc.de.300.bin\n",
      "Finished loading model for de with method: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import shutil\n",
    "\n",
    "marker = \"###################################\"\n",
    "\n",
    "# Combined language-specific configurations\n",
    "languages = {\n",
    "    'en': {\n",
    "        'full_name': 'English', \n",
    "        'model_path': 'models/cc.en.300.bin',\n",
    "        'exclude_words': [\"man\", \"woman\", \"Phil\", \"marv\", \"ole\", \"owld\", \"utd\"],\n",
    "        # \"particuler\", \"legendry\" -- archaic spellings\n",
    "        'genders': ['man', 'woman'],\n",
    "        'determiners': ['the'],\n",
    "        'personhood_word':'person',\n",
    "        'depersonalized_genders':['masculinity', 'femininity'],\n",
    "    },\n",
    "    'es': {\n",
    "        'full_name': 'Spanish', \n",
    "        'model_path': 'models/cc.es.300.bin',\n",
    "        'exclude_words': [\"hombre\", \"mujer\"],\n",
    "        'genders': ['hombre', 'mujer'],\n",
    "        'determiners': ['el', 'la'],\n",
    "        'personhood_word':'persona',\n",
    "        'depersonalized_genders':['masculinidad', 'femininidad'],\n",
    "    },\n",
    "    'de': {\n",
    "        'full_name': 'German', \n",
    "        'model_path': 'models/cc.de.300.bin',\n",
    "        'exclude_words': [\"Mann\", \"Frau\", \"mfG\", \"ein\"],\n",
    "        'genders': ['Mann', 'Frau'],\n",
    "        'determiners': ['der', 'die', 'das'],\n",
    "        'personhood_word':'Individuum',\n",
    "        'depersonalized_genders':['MÃ¤nnlichkeit', 'Weiblichkeit'],\n",
    "    }\n",
    "}\n",
    "\n",
    "columns = {\n",
    "    'masculine':'masculine_score',\n",
    "    'feminine':'feminine_score',\n",
    "}\n",
    "\n",
    "# Auto-generating parquet_paths based on languages\n",
    "parquet_paths = {lang: f\"adjectives/{lang}_adjectives.parquet\" for lang in languages.keys()}\n",
    "\n",
    "targets = ['masculine', 'feminine']\n",
    "\n",
    "nouns_df = pd.read_csv('nouns.csv')\n",
    "\n",
    "def load_model(language, method=\"normal\"):\n",
    "    \"\"\"\n",
    "    Loads model for the specified language to memory.\n",
    "    params:\n",
    "        language: (string) two letter language code\n",
    "        method: (string) 'facebook' or 'normal'\n",
    "    \"\"\"\n",
    "    print(f'Loading model for {language} with method: {method}')\n",
    "    model_path = languages[language]['model_path']\n",
    "    print(model_path)\n",
    "    if method == 'normal': \n",
    "        model = fasttext.load_model(model_path)\n",
    "    else:\n",
    "        model = load_facebook_model(model_path)\n",
    "    print(f'Finished loading model for {language} with method: {method}')\n",
    "    return model\n",
    "\n",
    "models = {lang: load_model(lang, method='normal') for lang in languages.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base functions\n",
    "def cossim(vec1, vec2):\n",
    "    \"\"\"Return cosine similarity between vec1 and vec2\"\"\"\n",
    "    dot_product = sum(a*b for a, b in zip(vec1, vec2))\n",
    "    magnitude1 = math.sqrt(sum([val**2 for val in vec1]))\n",
    "    magnitude2 = math.sqrt(sum([val**2 for val in vec2]))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def euclid(vec1, vec2):\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.linalg.norm(vec1 - vec2)\n",
    "\n",
    "def get(model, word):\n",
    "    \"\"\"Return word embedding for word as in model\"\"\"\n",
    "    return model.get_word_vector(word)\n",
    "\n",
    "def load_dataframe(file_path):\n",
    "    # Check the file extension\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "\n",
    "    # Load the file into a DataFrame based on its extension\n",
    "    if file_extension == '.csv':\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_extension == '.parquet':\n",
    "        df = pd.read_parquet(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def fetch_html_content(url):\n",
    "    \"\"\"Fetch HTML content from a given URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "# Wiktionary crawling\n",
    "def parse_adjectives(soup):\n",
    "    \"\"\"Parse and extract adjectives from BeautifulSoup object.\"\"\"\n",
    "    mw_category_groups = soup.find_all(class_=\"mw-category-group\")\n",
    "    adjectives = []\n",
    "    for group in mw_category_groups:\n",
    "        li_tags = group.find_all('li')\n",
    "        for li in li_tags:\n",
    "            adjective = li.get_text()\n",
    "            if not any(char.isdigit() for char in adjective) and \" \" not in adjective and \"-\" not in adjective and \"+\" not in adjective and \"&\" not in adjective and \"'\" not in adjective and \".\" not in adjective and \"(\" not in adjective:\n",
    "                adjectives.append(adjective)\n",
    "    return adjectives\n",
    "\n",
    "def find_next_page_url(soup):\n",
    "    \"\"\"Find the URL of the next page.\"\"\"\n",
    "    next_page_link = soup.find(\"a\", string=\"next page\")\n",
    "    return 'https://en.wiktionary.org' + next_page_link.get('href') if next_page_link else None\n",
    "\n",
    "def extract_adjectives(language, url, max_pages=None):\n",
    "    \"\"\"Extract adjectives from Wiktionary for a given language.\"\"\"\n",
    "    all_adjectives = []\n",
    "    page_count = 0\n",
    "    while url and (max_pages is None or page_count < max_pages):\n",
    "        html_content = fetch_html_content(url)\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        adjectives = parse_adjectives(soup)\n",
    "        all_adjectives.extend(adjectives)\n",
    "        url = find_next_page_url(soup)\n",
    "        page_count += 1\n",
    "    return all_adjectives\n",
    "\n",
    "def save_adjectives_to_parquet(adjectives, language_code, file_path):\n",
    "    \"\"\"Save adjectives to a parquet file.\"\"\"\n",
    "    df = pd.DataFrame(adjectives, columns=['Adjective'])\n",
    "    df['Language'] = language_code\n",
    "    df.to_parquet(file_path, index=False)\n",
    "\n",
    "def parse_nouns(soup):\n",
    "    \"\"\"Parse and extract nouns from BeautifulSoup object.\"\"\"\n",
    "    mw_category_groups = soup.find_all(class_=\"mw-category-group\")\n",
    "    nouns = []\n",
    "    for group in mw_category_groups:\n",
    "        li_tags = group.find_all('li')\n",
    "        for li in li_tags:\n",
    "            noun = li.get_text()\n",
    "            if not any(char.isdigit() for char in noun) and \" \" not in noun and \"-\" not in noun and \"+\" not in noun and \"&\" not in noun and \"'\" not in noun and \".\" not in noun and \"(\" not in noun:\n",
    "                nouns.append(noun)\n",
    "    return nouns\n",
    "\n",
    "def extract_nouns(language, url, max_pages=None):\n",
    "    \"\"\"Extract nouns from Wiktionary for a given language.\"\"\"\n",
    "    all_nouns = []\n",
    "    page_count = 0\n",
    "    while url and (max_pages is None or page_count < max_pages):\n",
    "        html_content = fetch_html_content(url)\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        nouns = parse_nouns(soup)  # Need to implement parse_nouns similar to parse_adjectives\n",
    "        all_nouns.extend(nouns)\n",
    "        url = find_next_page_url(soup)\n",
    "        page_count += 1\n",
    "    return all_nouns\n",
    "\n",
    "def save_nouns_to_parquet(nouns, language_code, file_path):\n",
    "    \"\"\"Save nouns to a parquet file with language and grammatical gender.\"\"\"\n",
    "    df = pd.DataFrame(nouns, columns=['Noun', 'Gender'])\n",
    "    df['Language'] = language_code\n",
    "    df.to_parquet(file_path, index=False)\n",
    "\n",
    "# Populate adjective list with gender similarity data\n",
    "def calculate_adjective_similarities(language_code, method=cossim):\n",
    "    \"\"\"Calculate gender-related similarities for adjectives in a given language.\"\"\"\n",
    "    # Load the Parquet file into a DataFrame\n",
    "    parquet_file_path = parquet_paths[language_code]\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "    # Load the word embedding model\n",
    "    language_data = languages[language_code]\n",
    "    model = models[language_code]\n",
    "\n",
    "    # Initialize columns for similarities\n",
    "    df['masculine_similarity'] = 0.0\n",
    "    df['feminine_similarity'] = 0.0\n",
    "    df['exclusive_masculine_similarity'] = 0.0\n",
    "    df['exclusive_feminine_similarity'] = 0.0\n",
    "    df['depersonalized_masculine_similarity'] = 0.0\n",
    "    df['depersonalized_feminine_similarity'] = 0.0\n",
    "\n",
    "    # Get target word embeddings\n",
    "    masculine_target = get(model, language_data['genders'][0])\n",
    "    feminine_target = get(model, language_data['genders'][1])\n",
    "    neuter_target = get(model, language_data['personhood_word'])\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    for index, row in df.iterrows():\n",
    "        word_vec = get(model, row['Adjective'])\n",
    "\n",
    "        # Regular similarities\n",
    "        df.at[index, 'masculine_similarity'] = method(word_vec, masculine_target)\n",
    "        df.at[index, 'feminine_similarity'] = method(word_vec, feminine_target)\n",
    "        df.at[index, 'neuter_similarity'] = method(word_vec, neuter_target)\n",
    "        df.at[index, 'depersonalized_masculine_similarity'] = method(word_vec, get(models[language_code], language_data['depersonalized_genders'][1]))\n",
    "        df.at[index, 'depersonalized_feminine_similarity'] = method(word_vec, get(models[language_code], language_data['depersonalized_genders'][0]))\n",
    "\n",
    "    # Save the updated DataFrame back to Parquet\n",
    "    df.to_parquet(parquet_file_path)\n",
    "\n",
    "def select_top_words(language_code, method, num_rows=1000, semantic_differential_vectors='gender1-gender2'):\n",
    "    # Load the Parquet file into a DataFrame\n",
    "    parquet_file_path = parquet_paths[language_code]\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    model = models[language_code]\n",
    "\n",
    "    # Access language-specific data\n",
    "    language_data = languages[language_code]\n",
    "\n",
    "    # debug lines vvvv\n",
    "    # method = 'cosine_similarity'\n",
    "    # semantic_differential_vectors = 'gender-Gender'\n",
    "    # ^^^^ debug lines\n",
    "    print('############### TOPWORDS CALLED #######################################################$$$$$$$$$$$$$$$$$$')\n",
    "\n",
    "    # Implement the semantic differential method\n",
    "    if method == 'semantic_differential':\n",
    "        print('############### SEMANTIC DIFFERNTIAL #######################################################$$$$$$$$$$$$$$$$$$')\n",
    "        if semantic_differential_vectors == 'gender1-gender2':\n",
    "            print('############### GENDER1-GENDER2 #######################################################$$$$$$$$$$$$$$$$$$')\n",
    "            df['masculine_score'] = df['masculine_similarity'] - df['feminine_similarity']\n",
    "            df['feminine_score'] = df['feminine_similarity'] - df['masculine_similarity']\n",
    "        elif semantic_differential_vectors == 'gender-person':\n",
    "            print('############### GENDER-PERSON #######################################################$$$$$$$$$$$$$$$$$$')\n",
    "            df['masculine_score'] = df['masculine_similarity'] - df['neuter_similarity']\n",
    "            df['feminine_score'] = df['feminine_similarity'] - df['neuter_similarity']\n",
    "        elif semantic_differential_vectors == 'gender-Gender':\n",
    "            print('############### GENDER-GENDER #######################################################$$$$$$$$$$$$$$$$$$')\n",
    "            df['masculine_score'] = df['masculine_similarity'] - df['depersonalized_feminine_similarity']\n",
    "            df['feminine_score'] = df['feminine_similarity'] - df['depersonalized_masculine_similarity']\n",
    "    if method == 'cosine_similarity':\n",
    "        print('############### COSINE SIMILARITY #######################################################$$$$$$$$$$$$$$$$$$')\n",
    "        df['masculine_score'] = df['masculine_similarity']\n",
    "        df['feminine_score'] = df['feminine_similarity']\n",
    "\n",
    "    # Filter out excluded words\n",
    "    exclude_list = language_data['exclude_words']\n",
    "    df = df[~df['Adjective'].isin(exclude_list)]\n",
    "\n",
    "    # Initialize empty DataFrames for selected words\n",
    "    selected_masculine = pd.DataFrame(columns=df.columns)\n",
    "    selected_feminine = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    while len(selected_masculine) < num_rows or len(selected_feminine) < num_rows:\n",
    "        if len(selected_masculine) < num_rows:\n",
    "            top_masculine = df.sort_values(by=columns['masculine'], ascending=False).head(num_rows * 2)\n",
    "            top_masculine = top_masculine[~top_masculine['Adjective'].isin(selected_feminine['Adjective'])].head(num_rows - len(selected_masculine))\n",
    "            selected_masculine = pd.concat([selected_masculine, top_masculine])\n",
    "\n",
    "        if len(selected_feminine) < num_rows:\n",
    "            top_feminine = df.sort_values(by=columns['feminine'], ascending=False).head(num_rows * 2)\n",
    "            top_feminine = top_feminine[~top_feminine['Adjective'].isin(selected_masculine['Adjective'])].head(num_rows - len(selected_feminine))\n",
    "            selected_feminine = pd.concat([selected_feminine, top_feminine])\n",
    "\n",
    "    # Save the selected words to Parquet files\n",
    "    masculine_file_path = f'adjectives/{language_code}_masculine_adjectives.parquet'\n",
    "    feminine_file_path = f'adjectives/{language_code}_feminine_adjectives.parquet'\n",
    "    selected_masculine.to_parquet(masculine_file_path, index=False)\n",
    "    selected_feminine.to_parquet(feminine_file_path, index=False)\n",
    "\n",
    "    return selected_masculine, selected_feminine\n",
    "\n",
    "def duplicate_spanish_adjectives(df, association):\n",
    "    \"\"\"\n",
    "    Adds an 'Alternate Form' column to the DataFrame of Spanish adjectives, \n",
    "    with the adjective from the 'Adjective' column having the opposite gender ending.\n",
    "    \"\"\"\n",
    "\n",
    "    # df['Alternate Form'] = df['Adjective']\n",
    "    print(f\"Added 'Alternate Form' to Spanish {association} adjectives parquet file\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        adjective = row['Adjective']\n",
    "        if adjective.endswith('o'):  # masculine to feminine\n",
    "            df.at[index, 'Alternate Form'] = adjective[:-1] + 'a'\n",
    "            print(f\"Added alternate form {adjective[:-1] + 'a'} for adjective: {adjective}\")\n",
    "        elif adjective.endswith('a'):  # feminine to masculine\n",
    "            df.at[index, 'Alternate Form'] = adjective[:-1] + 'o'\n",
    "            print(f\"Added alternate form {adjective[:-1] + 'o'} for adjective: {adjective}\")\n",
    "\n",
    "    masculine_file_path = f'adjectives/es_masculine_adjectives.parquet'\n",
    "    feminine_file_path = f'adjectives/es_feminine_adjectives.parquet'  \n",
    "    df.to_parquet(masculine_file_path if association == 'masculine' else feminine_file_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_similarity(model, words, target_words, ref_group_label, language, ref_association, target_group):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between word vectors and target vectors.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for word in words:\n",
    "        word_vec = get(model, word)\n",
    "        for target_word in target_words:\n",
    "            target_vec = get(model, target_word)\n",
    "            similarity = cossim(word_vec, target_vec)\n",
    "            results.append({\n",
    "                'LANGUAGE': language,\n",
    "                'REFERENCE GROUP': ref_group_label,\n",
    "                'REFERENCE ASSOCIATION': ref_association,\n",
    "                'REFERENCE WORD': word,\n",
    "                'TARGET GROUP': target_group,\n",
    "                'TARGET WORD': target_word,\n",
    "                'COSINE SIMILARITY': similarity\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def create_control_test_dataframe(lang_code, nouns_df, model):\n",
    "    print(f\"Creating control test dataframe for language: {lang_code}\")\n",
    "    control_test_data = []\n",
    "\n",
    "    # Process nouns\n",
    "    nouns_lang_df = nouns_df[nouns_df['LANGUAGE'] == lang_code]\n",
    "    for noun_gender in nouns_lang_df['ASSOCIATION/GRAMMATICAL GENDER'].unique():\n",
    "        print(f\"Processing nouns for gender: {noun_gender}\")\n",
    "        nouns = nouns_lang_df[nouns_lang_df['ASSOCIATION/GRAMMATICAL GENDER'] == noun_gender]['WORD'].tolist()\n",
    "        for target_group in ['genders', 'determiners']:\n",
    "            print(f\"Calculating similarities for nouns with {target_group}\")\n",
    "            target_words = languages[lang_code][target_group]\n",
    "            for target_word in target_words:\n",
    "                data = calculate_similarity(model, nouns, [target_word], 'nouns', lang_code, noun_gender, target_group)\n",
    "                control_test_data.append(data)\n",
    "\n",
    "    # Process adjectives for each gender association\n",
    "    for adj_association in targets:\n",
    "        print(f\"Processing {adj_association} adjectives\")\n",
    "        adjectives_df = pd.read_parquet(f'adjectives/{lang_code}_{adj_association}_adjectives.parquet')\n",
    "        adjectives = adjectives_df['Adjective'].tolist()\n",
    "        for target_group in ['genders', 'determiners']:\n",
    "            print(f\"Calculating similarities for {adj_association} adjectives with {target_group}\")\n",
    "            target_words = languages[lang_code][target_group]\n",
    "            for target_word in target_words:\n",
    "                data = calculate_similarity(model, adjectives, [target_word], 'adjectives', lang_code, adj_association, target_group)\n",
    "                control_test_data.append(data)\n",
    "\n",
    "            if lang_code == 'es':\n",
    "                alternate_forms = adjectives_df['Alternate Form'].dropna().tolist()\n",
    "                for target_word in target_words:\n",
    "                    for alternate_form in alternate_forms:\n",
    "                        if alternate_form:  # Check if alternate form is not None\n",
    "                            data = calculate_similarity(model, [alternate_form], [target_word], 'adjectives', lang_code, adj_association, target_group)\n",
    "                            control_test_data.append(data)\n",
    "    combined_data = pd.concat(control_test_data, ignore_index=True)\n",
    "    print(\"Columns in control_data DataFrame:\", combined_data.columns.tolist())\n",
    "    print(f\"Control test dataframe created for language: {lang_code}, Rows: {combined_data.shape[0]}\")\n",
    "    print(f\"Control test dataframe created for language: {lang_code}, Rows: {combined_data.shape[0]}\")\n",
    "    return combined_data\n",
    "\n",
    "def create_experimental_test_dataframe(lang_code, nouns_df, model, use_groupby=False):\n",
    "    print(f\"Creating experimental test dataframe for language: {lang_code}\")\n",
    "    experimental_test_data = []\n",
    "\n",
    "    nouns_lang_df = nouns_df[nouns_df['LANGUAGE'] == lang_code]\n",
    "\n",
    "    for adj_association in ['masculine', 'feminine']:\n",
    "        adjectives_df = pd.read_parquet(f'adjectives/{lang_code}_{adj_association}_adjectives.parquet')\n",
    "        adjectives = adjectives_df['Adjective'].tolist()\n",
    "\n",
    "        if lang_code == 'es':\n",
    "            alternate_forms = adjectives_df['Alternate Form'].dropna().tolist()\n",
    "\n",
    "            for noun_gender in nouns_lang_df['ASSOCIATION/GRAMMATICAL GENDER'].unique():\n",
    "                nouns = nouns_lang_df[nouns_lang_df['ASSOCIATION/GRAMMATICAL GENDER'] == noun_gender]['WORD'].tolist()\n",
    "                for noun in nouns:\n",
    "                    for alternate_form in alternate_forms:  # Include alternate forms in the loop\n",
    "                        if alternate_form:  # Check if alternate form is not None\n",
    "                            similarity = cossim(model.get_word_vector(noun), model.get_word_vector(alternate_form))\n",
    "                            experimental_test_data.append({\n",
    "                                'LANGUAGE': lang_code,\n",
    "                                'GRAMMATICAL GENDER OF NOUN': noun_gender,\n",
    "                                'NOUN': noun,\n",
    "                                'ADJECTIVE': alternate_form,\n",
    "                                'COSINE SIMILARITY': similarity,\n",
    "                                'GENDER ASSOCIATION OF ADJECTIVE': adj_association\n",
    "                            })\n",
    "\n",
    "        for noun_gender in nouns_lang_df['ASSOCIATION/GRAMMATICAL GENDER'].unique():\n",
    "            nouns = nouns_lang_df[nouns_lang_df['ASSOCIATION/GRAMMATICAL GENDER'] == noun_gender]['WORD'].tolist()\n",
    "            for noun in nouns:\n",
    "                for adjective in adjectives:\n",
    "                    similarity = cossim(model.get_word_vector(noun), model.get_word_vector(adjective))\n",
    "                    experimental_test_data.append({\n",
    "                        'LANGUAGE': lang_code,\n",
    "                        'GRAMMATICAL GENDER OF NOUN': noun_gender,\n",
    "                        'NOUN': noun,\n",
    "                        'ADJECTIVE': adjective,\n",
    "                        'COSINE SIMILARITY': similarity,\n",
    "                        'GENDER ASSOCIATION OF ADJECTIVE': adj_association\n",
    "                    })\n",
    "\n",
    "    combined_data = pd.DataFrame(experimental_test_data)\n",
    "    \n",
    "    if use_groupby:\n",
    "        combined_data = combined_data.groupby(['LANGUAGE', 'GRAMMATICAL GENDER OF NOUN', 'NOUN', 'GENDER ASSOCIATION OF ADJECTIVE'])['COSINE SIMILARITY'].mean().reset_index()\n",
    "\n",
    "    print(f\"Experimental test dataframe created for language: {lang_code}, Rows: {combined_data.shape[0]}\")\n",
    "    return combined_data\n",
    "\n",
    "def plot_and_save(df, title, filename, plot_type, ref_group, font_size):\n",
    "    print(f\"Plotting: {title}\")\n",
    "    if df.empty:\n",
    "        print(f\"No data to plot for {title}\")\n",
    "        return\n",
    "    \n",
    "    mpl.rcParams['font.size'] = font_size  # Adjust this value as needed\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    order = None\n",
    "    hue_order = None\n",
    "\n",
    "    try:\n",
    "        if ref_group == 'nouns':\n",
    "            # For control tests with nouns as the reference group\n",
    "            x_col = 'REFERENCE ASSOCIATION'  # Column in DataFrame\n",
    "            hue_col = 'TARGET WORD'\n",
    "            x_label = 'Grammatical Gender of Noun'  # Label for x-axis\n",
    "            legend_title = 'Target Word'\n",
    "            if 'English' not in title:  \n",
    "                order = targets\n",
    "        elif ref_group == 'adjectives':\n",
    "            # For control tests with adjectives as the reference group\n",
    "            x_col = 'REFERENCE ASSOCIATION'\n",
    "            hue_col = 'TARGET WORD'\n",
    "            x_label = 'Gender Association of Adjective'\n",
    "            legend_title = 'Target Word'\n",
    "            order = targets\n",
    "        else:\n",
    "            # For experimental tests\n",
    "            x_col = 'GRAMMATICAL GENDER OF NOUN'\n",
    "            hue_col = 'GENDER ASSOCIATION OF ADJECTIVE'\n",
    "            x_label = 'Grammatical Gender of Noun'\n",
    "            legend_title = 'Gender Association of Adjective'\n",
    "            if 'English' not in title:  \n",
    "                order = targets\n",
    "            hue_order = targets \n",
    "\n",
    "        if plot_type == 'box':\n",
    "            sns.boxplot(x=x_col, y='COSINE SIMILARITY', hue=hue_col, data=df, order=order, hue_order=hue_order)\n",
    "        elif plot_type == 'strip':\n",
    "            sns.stripplot(x=x_col, y='COSINE SIMILARITY', hue=hue_col, data=df, dodge=True, order=order, hue_order=hue_order)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel('Cosine Similarity')\n",
    "        plt.legend(title=legend_title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "        print(f\"Plot saved: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{marker}Error in plotting: {e}\")\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def plot_adjective_targets_nouns(lang_code, control_data, nouns_df, model):\n",
    "    if lang_code == 'en':\n",
    "        return\n",
    "\n",
    "    def generate_plot(data_dict, plot_title, file_name):\n",
    "        plot_data = pd.DataFrame(data_dict)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
    "        plt.title(plot_title)\n",
    "        plt.xlabel('Similarity to Gender Word')\n",
    "        plt.ylabel('Avg Similarity to Gender Nouns')\n",
    "        plt.legend(title='Adjective Association')\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()\n",
    "\n",
    "    def process_adjectives(adj_association, gender_word):\n",
    "        data_dict = {'Adjective': [], 'Association': [], 'Similarity to Gender Word': [], 'Avg Similarity to Gender Nouns': []}\n",
    "        adjective_data = control_data[(control_data['REFERENCE GROUP'] == 'adjectives') & (control_data['REFERENCE ASSOCIATION'] == adj_association) & (control_data['TARGET GROUP'] == 'genders')]\n",
    "\n",
    "        for adj in adjective_data['REFERENCE WORD'].unique():\n",
    "            sim_to_gender_word = cossim(model.get_word_vector(adj), model.get_word_vector(gender_word))\n",
    "            avg_similarity = np.mean([cossim(model.get_word_vector(adj), model.get_word_vector(noun)) for noun in gender_nouns])\n",
    "\n",
    "            data_dict['Adjective'].append(adj)\n",
    "            data_dict['Association'].append(adj_association)\n",
    "            data_dict['Similarity to Gender Word'].append(sim_to_gender_word)\n",
    "            data_dict['Avg Similarity to Gender Nouns'].append(avg_similarity)\n",
    "        \n",
    "        return data_dict\n",
    "\n",
    "    for target_gender in ['masculine', 'feminine']:\n",
    "        for gender_word_vec in ['man', 'woman']:\n",
    "            gender_word = languages[lang_code]['genders'][0] if gender_word_vec == 'man' else languages[lang_code]['genders'][1]\n",
    "            gender_nouns = nouns_df[(nouns_df['LANGUAGE'] == lang_code) & (nouns_df['ASSOCIATION/GRAMMATICAL GENDER'] == target_gender)]['WORD'].tolist()\n",
    "\n",
    "            # Regular plots\n",
    "            for adj_association in ['masculine', 'feminine']:\n",
    "                data_dict = process_adjectives(adj_association, gender_word)\n",
    "                plot_title = f\"{lang_code} Adjectives: {gender_word.capitalize()} vs {target_gender.capitalize()} Nouns\"\n",
    "                file_name = f\"plots/scatters/{lang_code}_{gender_word_vec}_{target_gender}_adjectives_vs_nouns.png\"\n",
    "                generate_plot(data_dict, plot_title, file_name)\n",
    "\n",
    "            # Additional plots for Spanish with averaged forms\n",
    "            if lang_code == 'es':\n",
    "                avg_data_dict = {'Adjective': [], 'Association': [], 'Similarity to Gender Word': [], 'Avg Similarity to Gender Nouns': []}\n",
    "                adjs_processed = set()\n",
    "\n",
    "                for adj_association in ['masculine', 'feminine']:\n",
    "                    data_dict = process_adjectives(adj_association, gender_word)\n",
    "\n",
    "                    for adj, sim, avg_sim in zip(data_dict['Adjective'], data_dict['Similarity to Gender Word'], data_dict['Avg Similarity to Gender Nouns']):\n",
    "                        if adj.endswith('o') or adj.endswith('a'):\n",
    "                            base_adj = adj[:-1]\n",
    "                            alt_form = base_adj + ('o' if adj.endswith('a') else 'a')\n",
    "\n",
    "                            if alt_form in data_dict['Adjective'] and adj not in adjs_processed:\n",
    "                                alt_sim = data_dict['Similarity to Gender Word'][data_dict['Adjective'].index(alt_form)]\n",
    "                                alt_avg_sim = data_dict['Avg Similarity to Gender Nouns'][data_dict['Adjective'].index(alt_form)]\n",
    "\n",
    "                                avg_data_dict['Adjective'].append(base_adj)\n",
    "                                avg_data_dict['Association'].append(adj_association)\n",
    "                                avg_data_dict['Similarity to Gender Word'].append(np.mean([sim, alt_sim]))\n",
    "                                avg_data_dict['Avg Similarity to Gender Nouns'].append(np.mean([avg_sim, alt_avg_sim]))\n",
    "\n",
    "                                adjs_processed.add(adj)\n",
    "                                adjs_processed.add(alt_form)\n",
    "                        elif adj not in adjs_processed:\n",
    "                            avg_data_dict['Adjective'].append(adj)\n",
    "                            avg_data_dict['Association'].append(adj_association)\n",
    "                            avg_data_dict['Similarity to Gender Word'].append(sim)\n",
    "                            avg_data_dict['Avg Similarity to Gender Nouns'].append(avg_sim)\n",
    "\n",
    "                            adjs_processed.add(adj)\n",
    "\n",
    "                plot_title = f\"{lang_code} Adjectives (Avg'd Forms): {gender_word.capitalize()} vs {target_gender.capitalize()} Nouns\"\n",
    "                file_name = f\"plots/scatters/{lang_code}_{gender_word_vec}_{target_gender}_adjectives_avgd_forms_vs_nouns.png\"\n",
    "                generate_plot(avg_data_dict, plot_title, file_name)\n",
    "\n",
    "\n",
    "def write_statistics_to_report(df, title, report_filename):\n",
    "    print(f\"Writing statistics to report: {report_filename}\")\n",
    "    with open(report_filename, 'w') as report_file:\n",
    "        if df.empty:\n",
    "            report_file.write(f\"No data available for {title}\\n\\n\")\n",
    "            return\n",
    "\n",
    "        if 'REFERENCE GROUP' in df.columns:\n",
    "            group_cols = ['LANGUAGE', 'REFERENCE GROUP', 'TARGET GROUP']\n",
    "        elif 'GRAMMATICAL GENDER OF NOUN' in df.columns:\n",
    "            group_cols = ['LANGUAGE', 'GRAMMATICAL GENDER OF NOUN', 'GENDER ASSOCIATION OF ADJECTIVE']\n",
    "        else:\n",
    "            report_file.write(\"Unexpected DataFrame structure.\\n\")\n",
    "            return\n",
    "\n",
    "        stats = df.groupby(group_cols)['COSINE SIMILARITY'].describe()\n",
    "        report_file.write(f\"Statistics for {title}:\\n{stats}\\n\\n\")\n",
    "    print(f\"Report written: {report_filename}\")\n",
    "\n",
    "def find_adjective_definition(adjective):\n",
    "    print(f'Finding definition for word: {adjective}')\n",
    "    # Adjust URL for English definitions regardless of the adjective's language\n",
    "    url = f\"https://en.wiktionary.org/wiki/{adjective}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Attempt to find the definition section for adjectives\n",
    "        definition_section = soup.find('span', {'class': 'mw-headline'}, text='Adjective')\n",
    "        if definition_section:\n",
    "            definition_list = definition_section.find_next('ol')\n",
    "            if definition_list:\n",
    "                first_item = definition_list.find('li')\n",
    "                if first_item:\n",
    "                    definition = first_item.get_text(separator=' ', strip=True).split('.')[0]\n",
    "                    return definition\n",
    "\n",
    "    except requests.HTTPError as e:\n",
    "        print(f\"Error retrieving page for {adjective}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {adjective}: {e}\")\n",
    "\n",
    "    return \"Definition not found\"\n",
    "\n",
    "def remove_adjective_duplicates(lang_code, columns):\n",
    "    # Load CSV files for masculine and feminine adjectives\n",
    "    masculine_csv = f'adjectives/{lang_code}_masculine_adjectives.csv'\n",
    "    feminine_csv = f'adjectives/{lang_code}_feminine_adjectives.csv'\n",
    "    df_masculine = pd.read_csv(masculine_csv)\n",
    "    df_feminine = pd.read_csv(feminine_csv)\n",
    "\n",
    "    # Additional handling for Spanish adjectives\n",
    "    if lang_code == 'es':\n",
    "        for adj in df_masculine['Adjective']:\n",
    "            if adj.endswith('o'):\n",
    "                adj_root = adj[:-1]\n",
    "                # Check if feminine form exists\n",
    "                feminine_form = adj_root + 'a'\n",
    "                if feminine_form in df_feminine['Adjective'].values:\n",
    "                    # Compare and remove based on score\n",
    "                    masculine_score = df_masculine.loc[df_masculine['Adjective'] == adj, columns['masculine']].values[0]\n",
    "                    feminine_score = df_feminine.loc[df_feminine['Adjective'] == feminine_form, columns['feminine']].values[0]\n",
    "                    if masculine_score > feminine_score:\n",
    "                        df_feminine = df_feminine[df_feminine['Adjective'] != feminine_form]\n",
    "                    elif feminine_score > masculine_score:\n",
    "                        df_masculine = df_masculine[df_masculine['Adjective'] != adj]\n",
    "\n",
    "    # Continue with the original functionality for non-Spanish languages or non-gender inflected adjectives\n",
    "    common_adjectives = set(df_masculine['Adjective']).intersection(df_feminine['Adjective'])\n",
    "    for adj in common_adjectives:\n",
    "        masculine_score = df_masculine.loc[df_masculine['Adjective'] == adj, columns['masculine']].values[0]\n",
    "        feminine_score = df_feminine.loc[df_feminine['Adjective'] == adj, columns['feminine']].values[0]\n",
    "        if masculine_score > feminine_score:\n",
    "            df_feminine = df_feminine[df_feminine['Adjective'] != adj]\n",
    "        elif feminine_score > masculine_score:\n",
    "            df_masculine = df_masculine[df_masculine['Adjective'] != adj]\n",
    "\n",
    "    # Save the updated CSV files\n",
    "    df_masculine.to_csv(masculine_csv, index=False)\n",
    "    df_feminine.to_csv(feminine_csv, index=False)\n",
    "    print(f\"Updated CSV files for {lang_code}: removed duplicates with lower scores.\")\n",
    "\n",
    "def create_adjective_review_csv(parquet_file):\n",
    "    file_name = os.path.basename(parquet_file)\n",
    "    language_code, gender = file_name.split('_')[:2]\n",
    "    print(f'Creating review sheet for language: {language_code}')\n",
    "\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    df['Definition'] = df['Adjective'].apply(lambda x: find_adjective_definition(x))\n",
    "\n",
    "    # Determine which similarity scores to include based on gender\n",
    "    similarity_score_col = f\"{gender.lower()}_similarity\"\n",
    "    score_col = f\"{gender.lower()}_score\"\n",
    "\n",
    "    reviews_dir = 'adjectives'\n",
    "    df_sorted = df.sort_values(columns[gender], ascending=False)\n",
    "\n",
    "    csv_file_path = os.path.join(reviews_dir, file_name.replace('.parquet', '.csv'))\n",
    "    df_sorted.to_csv(csv_file_path, index=False)\n",
    "    print(f\"File saved as {csv_file_path}\")\n",
    "\n",
    "def find_minimum_length(languages, genders, unallowed_words):\n",
    "    min_length = float('inf')\n",
    "    for lang_code in languages:\n",
    "        for gender in genders:\n",
    "            parquet_file = f'adjectives/{lang_code}_{gender}_adjectives.parquet'\n",
    "            df = pd.read_parquet(parquet_file)\n",
    "            df = df[~df['Adjective'].isin(unallowed_words)]  # Remove unallowed words\n",
    "            min_length = min(min_length, len(df))\n",
    "    return min_length\n",
    "\n",
    "def remove_unwanted_adjectives(csv_file, allowed_words, unallowed_words, markers, min_length, gender):\n",
    "    # Load data from CSV file\n",
    "    csv_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract language code from filename\n",
    "    lang_code = csv_file[:2]\n",
    "\n",
    "    # Convert 'Adjective' column to string type for consistency\n",
    "    csv_df['Adjective'] = csv_df['Adjective'].astype(str)\n",
    "\n",
    "    # Preprocess unallowed_words for Spanish adjectives\n",
    "    if lang_code == 'es':\n",
    "        processed_unallowed = set()\n",
    "        for word in unallowed_words:\n",
    "            if word.endswith('o') or word.endswith('a'):\n",
    "                processed_unallowed.add(word[:-1])\n",
    "            else:\n",
    "                processed_unallowed.add(word)\n",
    "        unallowed_words = processed_unallowed\n",
    "\n",
    "    # Filter: Remove unallowed words\n",
    "    csv_df = csv_df[~csv_df['Adjective'].apply(lambda x: x[:-1] if (x.endswith('o') or x.endswith('a')) else x).isin(unallowed_words)]\n",
    "\n",
    "    # Filter: Remove words with unwanted markers, unless they are in allowed words\n",
    "    csv_df = csv_df[(~csv_df['Definition'].apply(lambda x: any(marker in x for marker in markers)) | csv_df['Adjective'].isin(allowed_words))]\n",
    "\n",
    "    # Sort and Trim: Keep only the top n rows based on score\n",
    "    score_col = columns[gender]\n",
    "    csv_df = csv_df.sort_values(by=score_col, ascending=False).head(min_length)\n",
    "\n",
    "    # Save the updated DataFrame back to CSV and Parquet\n",
    "    csv_df.to_csv(csv_file, index=False)\n",
    "    parquet_file = csv_file.replace('.csv', '.parquet')\n",
    "    csv_df.to_parquet(parquet_file, index=False)\n",
    "\n",
    "    print(f\"Updated DataFrame saved as {csv_file} and {parquet_file}\")\n",
    "\n",
    "    return csv_df\n",
    "\n",
    "def create_adjective_stimulus_files(csv_file):\n",
    "    # Define the directory where the copied files will be stored\n",
    "    target_dir = 'adjectives/stimulus_files'\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # Define the path for the target file\n",
    "    target_file_path = os.path.join(target_dir, os.path.basename(csv_file))\n",
    "\n",
    "    # Copy the file\n",
    "    shutil.copyfile(csv_file, target_file_path)\n",
    "    print(f\"Copied {csv_file} to {target_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(procedures, nouns_file, adjective_gender_association_method, top_n_adjectives, load_method, models, plot_type, use_groupby, semantic_differential_vectors, remove_adjectives_with_markers, unallowed_words, allowed_words, font_size):\n",
    "    nouns_df = load_dataframe(nouns_file)\n",
    "    min_length = top_n_adjectives\n",
    "    if adjective_gender_association_method == 'cosine_similarity':\n",
    "        for gender in columns.keys(): columns[gender] = f'{gender}_similarity'\n",
    "    elif adjective_gender_association_method == 'semantic_differential':\n",
    "        for gender in columns.keys(): columns[gender] = f'{gender}_score'\n",
    "    if procedures['load_models']:\n",
    "        # Load models for each language\n",
    "        models = {lang: load_model(lang, load_method) for lang in languages}\n",
    "\n",
    "    # Extract and save nouns and adjectives from Wiktionary if required\n",
    "    if procedures['crawl_wiktionary_nouns'] or procedures['crawl_wiktionary_adjectives']:\n",
    "        for lang_code, lang_data in languages.items():\n",
    "            if procedures['crawl_wiktionary_nouns']:\n",
    "                # Nouns extraction and saving\n",
    "                nouns_url = f'https://en.wiktionary.org/wiki/Category:{lang_data[\"full_name\"]}_nouns'\n",
    "                nouns = extract_nouns(lang_code, nouns_url)\n",
    "                save_nouns_to_parquet(nouns, lang_code, f'nouns/{lang_code}_nouns.parquet')\n",
    "\n",
    "            if procedures['crawl_wiktionary_adjectives']:\n",
    "                # Adjectives extraction and saving\n",
    "                adjectives_url = f'https://en.wiktionary.org/wiki/Category:{lang_data[\"full_name\"]}_adjectives'\n",
    "                adjectives = extract_adjectives(lang_code, adjectives_url)\n",
    "                save_adjectives_to_parquet(adjectives, lang_code, f'adjectives/{lang_code}_adjectives.parquet')\n",
    "\n",
    "    if procedures['calculate_adjective_similarities']:\n",
    "        # Populate adjective list with gender similarity data\n",
    "        for lang_code in languages.keys():\n",
    "            print(f\"Performing gender similarity calculations for {languages[lang_code]['full_name']}...\")\n",
    "            calculate_adjective_similarities(lang_code)\n",
    "            print(f\"Calculations completed for {languages[lang_code]['full_name']}.\")\n",
    "\n",
    "    if procedures['select_top_adjectives']:\n",
    "        # Select the top n most masculine or feminine adjectives\n",
    "        for lang_code in languages.keys():\n",
    "            masculine, feminine = select_top_words(lang_code, num_rows=top_n_adjectives, method=adjective_gender_association_method, semantic_differential_vectors=semantic_differential_vectors)\n",
    "            if lang_code == 'es':\n",
    "                masculine, feminine = duplicate_spanish_adjectives(masculine, 'masculine'), duplicate_spanish_adjectives(feminine, 'feminine')\n",
    "            print(f\"Selected top adjectives for {languages[lang_code]['full_name']}: Masculine: {len(masculine)}, Feminine: {len(feminine)}\")\n",
    "    \n",
    "    if procedures['remove_adjective_duplicates']:\n",
    "        for lang_code in languages.keys():\n",
    "            remove_adjective_duplicates(lang_code, columns)\n",
    "        \n",
    "    # Turn Parquet files into csv files for manual inspection or readability during communication\n",
    "    if procedures['adjective_definition_review']:\n",
    "        for lang_code in languages.keys():\n",
    "            for gender in targets:\n",
    "                create_adjective_review_csv(f'adjectives/{lang_code}_{gender}_adjectives.parquet')\n",
    "\n",
    "    if procedures['remove_unwanted_adjectives']:\n",
    "        for lang_code in ['en', 'es', 'de']:\n",
    "            for gender in ['masculine', 'feminine']:\n",
    "                csv_file = f'adjectives/{lang_code}_{gender}_adjectives.csv'\n",
    "                parquet_file = f'adjectives/{lang_code}_{gender}_adjectives.parquet'\n",
    "                min_length = find_minimum_length(languages, targets, unallowed_words)\n",
    "                remove_unwanted_adjectives(csv_file, allowed_words, unallowed_words, remove_adjectives_with_markers, min_length, gender)\n",
    "\n",
    "    if procedures['create_stimulus_files']:\n",
    "        min_length = find_minimum_length(languages, targets, unallowed_words)\n",
    "\n",
    "        for lang_code in languages:\n",
    "            for gender in targets:\n",
    "                csv_file = f'adjectives/{lang_code}_{gender}_adjectives.csv'\n",
    "                create_adjective_stimulus_files(csv_file)\n",
    "\n",
    "            # Iterate through each language\n",
    "    for lang_code, lang_data in languages.items():\n",
    "        print(f\"Processing language: {lang_data['full_name']}\")\n",
    "        model = models[lang_code]\n",
    "\n",
    "        # Conduct Control Tests\n",
    "        if procedures['conduct_control_tests']:\n",
    "            print(f\"Conducting control tests for {lang_data['full_name']}\")\n",
    "            control_data_dir = f'control_data/{lang_code}'\n",
    "            os.makedirs(control_data_dir, exist_ok=True)\n",
    "\n",
    "            control_data = create_control_test_dataframe(lang_code, nouns_df, model)\n",
    "            control_data.to_parquet(f'{control_data_dir}/{lang_code}_control_data.parquet')\n",
    "\n",
    "            for ref_group in ['nouns', 'adjectives']:\n",
    "                for target_group in ['genders', 'determiners']:\n",
    "                    plot_title = f'{lang_data[\"full_name\"]}: {ref_group.capitalize()} - {target_group.capitalize()}'\n",
    "                    plot_filename = f'plots/{lang_code}/{lang_code}_{ref_group}-{target_group}_{plot_type}.png'\n",
    "                    filtered_data = control_data[(control_data['REFERENCE GROUP'] == ref_group) & (control_data['TARGET GROUP'] == target_group)]\n",
    "                    plot_and_save(filtered_data, plot_title, plot_filename, plot_type, ref_group, font_size)  # Include ref_group\n",
    "                    report_filename = f'reports/{lang_code}_control_report.txt'\n",
    "                    write_statistics_to_report(filtered_data, plot_title, report_filename)\n",
    "            \n",
    "            # Call the plotting function for each adjective association\n",
    "            for adj_association in targets:\n",
    "                control_data = create_control_test_dataframe(lang_code, nouns_df, model)\n",
    "                control_data.to_parquet(f'{control_data_dir}/{lang_code}_control_data.parquet')\n",
    "\n",
    "                # Call the plotting function\n",
    "                plot_adjective_targets_nouns(lang_code, control_data, nouns_df, model)\n",
    "            \n",
    "        # Conduct Experimental Tests\n",
    "        if procedures['conduct_experimental_tests']:\n",
    "            \n",
    "            print(f\"Conducting experimental tests for {lang_data['full_name']}\")\n",
    "            test_data_dir = f'test_data/{lang_code}'\n",
    "            os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "            experimental_data = create_experimental_test_dataframe(lang_code, nouns_df, model, use_groupby)\n",
    "            experimental_data.to_parquet(f'{test_data_dir}/{lang_code}_test_data.parquet')\n",
    "\n",
    "            plot_title = f'{lang_data[\"full_name\"]}: Nouns - Adjectives'\n",
    "            plot_filename = f'plots/{lang_code}/{lang_code}_nouns-adjectives_{plot_type}.png'\n",
    "            plot_and_save(experimental_data, plot_title, plot_filename, plot_type, 'experimental', font_size)  # Added 'experimental' as the ref_group for experimental tests\n",
    "            report_filename = f'reports/{lang_code}_experimental_report.txt'\n",
    "            write_statistics_to_report(experimental_data, plot_title, report_filename)\n",
    "\n",
    "    print(\"Finished processing, plotting, and generating reports for tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### TOPWORDS CALLED #######################################################$$$$$$$$$$$$$$$$$$\n",
      "############### COSINE SIMILARITY #######################################################$$$$$$$$$$$$$$$$$$\n",
      "Added 'Alternate Form' to Spanish masculine adjectives parquet file\n",
      "Added alternate form individua for adjective: individuo\n",
      "Added alternate form humana for adjective: humano\n",
      "Added alternate form chica for adjective: chico\n",
      "Added alternate form anciana for adjective: anciano\n",
      "Added alternate form sabia for adjective: sabio\n",
      "Added alternate form jovencita for adjective: jovencito\n",
      "Added alternate form campesina for adjective: campesino\n",
      "Added alternate form adinerada for adjective: adinerado\n",
      "Added alternate form fornida for adjective: fornido\n",
      "Added alternate form sujeta for adjective: sujeto\n",
      "Added alternate form desgraciada for adjective: desgraciado\n",
      "Added alternate form vagabunda for adjective: vagabundo\n",
      "Added alternate form guapa for adjective: guapo\n",
      "Added alternate form cristiana for adjective: cristiano\n",
      "Added alternate form desdichada for adjective: desdichado\n",
      "Added alternate form barbuda for adjective: barbudo\n",
      "Added alternate form corpulenta for adjective: corpulento\n",
      "Added alternate form vieja for adjective: viejo\n",
      "Added alternate form perra for adjective: perro\n",
      "Added alternate form soltera for adjective: soltero\n",
      "Added alternate form afortunada for adjective: afortunado\n",
      "Added alternate form guerrera for adjective: guerrero\n",
      "Added alternate form camionera for adjective: camionero\n",
      "Added alternate form polifacÃ©tica for adjective: polifacÃ©tico\n",
      "Added alternate form vaquera for adjective: vaquero\n",
      "Added alternate form necia for adjective: necio\n",
      "Added alternate form asesina for adjective: asesino\n",
      "Added alternate form visionaria for adjective: visionario\n",
      "Added alternate form piadosa for adjective: piadoso\n",
      "Added alternate form madura for adjective: maduro\n",
      "Added alternate form acaudalada for adjective: acaudalado\n",
      "Added alternate form macha for adjective: macho\n",
      "Added alternate form mona for adjective: mono\n",
      "Added alternate form poderosa for adjective: poderoso\n",
      "Added alternate form encarnada for adjective: encarnado\n",
      "Added alternate form honrada for adjective: honrado\n",
      "Added alternate form primitiva for adjective: primitivo\n",
      "Added alternate form hombruna for adjective: hombruno\n",
      "Added alternate form octogenaria for adjective: octogenario\n",
      "Added alternate form masculina for adjective: masculino\n",
      "Added alternate form ruda for adjective: rudo\n",
      "Added alternate form depravada for adjective: depravado\n",
      "Added alternate form buenmoza for adjective: buenmozo\n",
      "Added alternate form caballerosa for adjective: caballeroso\n",
      "Added alternate form astuta for adjective: astuto\n",
      "Added alternate form atea for adjective: ateo\n",
      "Added alternate form forzuda for adjective: forzudo\n",
      "Added alternate form embarazada for adjective: embarazado\n",
      "Added alternate form ciudadana for adjective: ciudadano\n",
      "Added alternate form mujeriega for adjective: mujeriego\n",
      "Added alternate form intrÃ©pida for adjective: intrÃ©pido\n",
      "Added alternate form civilizada for adjective: civilizado\n",
      "Added alternate form aventurera for adjective: aventurero\n",
      "Added alternate form bondadosa for adjective: bondadoso\n",
      "Added alternate form semihumana for adjective: semihumano\n",
      "Added alternate form tÃ­mida for adjective: tÃ­mido\n",
      "Added alternate form cultÃ­sima for adjective: cultÃ­simo\n",
      "Added alternate form homÃ­nida for adjective: homÃ­nido\n",
      "Added alternate form adÃºltera for adjective: adÃºltero\n",
      "Added alternate form viuda for adjective: viudo\n",
      "Added alternate form mamÃ­fera for adjective: mamÃ­fero\n",
      "Added alternate form misteriosa for adjective: misterioso\n",
      "Added alternate form zoÃ³fila for adjective: zoÃ³filo\n",
      "Added alternate form zorra for adjective: zorro\n",
      "Added alternate form polÃ­gama for adjective: polÃ­gamo\n",
      "Added alternate form desalmada for adjective: desalmado\n",
      "Added alternate form sexuada for adjective: sexuado\n",
      "Added alternate form artesana for adjective: artesano\n",
      "Added alternate form vecina for adjective: vecino\n",
      "Added alternate form musculosa for adjective: musculoso\n",
      "Added alternate form afeminada for adjective: afeminado\n",
      "Added 'Alternate Form' to Spanish feminine adjectives parquet file\n",
      "Added alternate form feministo for adjective: feminista\n",
      "Added alternate form machisto for adjective: machista\n",
      "Added alternate form casada for adjective: casado\n",
      "Added alternate form hembristo for adjective: hembrista\n",
      "Added alternate form bollero for adjective: bollera\n",
      "Added alternate form femenina for adjective: femenino\n",
      "Added alternate form transgeneristo for adjective: transgenerista\n",
      "Added alternate form desposada for adjective: desposado\n",
      "Added alternate form profeministo for adjective: profeminista\n",
      "Added alternate form masculinizada for adjective: masculinizado\n",
      "Added alternate form transgÃ©nera for adjective: transgÃ©nero\n",
      "Added alternate form divorciada for adjective: divorciado\n",
      "Added alternate form sexisto for adjective: sexista\n",
      "Added alternate form activisto for adjective: activista\n",
      "Added alternate form lesbiana for adjective: lesbiano\n",
      "Added alternate form anarcofeministo for adjective: anarcofeminista\n",
      "Added alternate form hermafrodito for adjective: hermafrodita\n",
      "Added alternate form antifeministo for adjective: antifeminista\n",
      "Added alternate form pseudofeministo for adjective: pseudofeminista\n",
      "Added alternate form casadera for adjective: casadero\n",
      "Added alternate form travestida for adjective: travestido\n",
      "Added alternate form ultrafeministo for adjective: ultrafeminista\n",
      "Added alternate form enamorada for adjective: enamorado\n",
      "Added alternate form indÃ­geno for adjective: indÃ­gena\n",
      "Added alternate form travestisto for adjective: travestista\n",
      "Added alternate form enamoradÃ­sima for adjective: enamoradÃ­simo\n",
      "Added alternate form posfeministo for adjective: posfeminista\n",
      "Added alternate form infanticido for adjective: infanticida\n",
      "Added alternate form filicido for adjective: filicida\n",
      "Added alternate form primogÃ©nita for adjective: primogÃ©nito\n",
      "Added alternate form concubinaria for adjective: concubinario\n",
      "Added alternate form misÃ³gina for adjective: misÃ³gino\n",
      "Added alternate form israelito for adjective: israelita\n",
      "Added alternate form cornuda for adjective: cornudo\n",
      "Added alternate form misÃ¡ndrica for adjective: misÃ¡ndrico\n",
      "Added alternate form rato for adjective: rata\n",
      "Added alternate form madrera for adjective: madrero\n",
      "Added alternate form homicido for adjective: homicida\n",
      "Added alternate form cisgÃ©nera for adjective: cisgÃ©nero\n",
      "Added alternate form cavernÃ­colo for adjective: cavernÃ­cola\n",
      "Added alternate form nudisto for adjective: nudista\n",
      "Added alternate form polleruda for adjective: pollerudo\n",
      "Selected top adjectives for Spanish: Masculine: 100, Feminine: 100\n",
      "############### TOPWORDS CALLED #######################################################$$$$$$$$$$$$$$$$$$\n",
      "############### COSINE SIMILARITY #######################################################$$$$$$$$$$$$$$$$$$\n",
      "Selected top adjectives for German: Masculine: 100, Feminine: 100\n",
      "Updated CSV files for es: removed duplicates with lower scores.\n",
      "Updated CSV files for de: removed duplicates with lower scores.\n",
      "Updated DataFrame saved as adjectives/en_masculine_adjectives.csv and adjectives/en_masculine_adjectives.parquet\n",
      "Updated DataFrame saved as adjectives/en_feminine_adjectives.csv and adjectives/en_feminine_adjectives.parquet\n",
      "Updated DataFrame saved as adjectives/es_masculine_adjectives.csv and adjectives/es_masculine_adjectives.parquet\n",
      "Updated DataFrame saved as adjectives/es_feminine_adjectives.csv and adjectives/es_feminine_adjectives.parquet\n",
      "Updated DataFrame saved as adjectives/de_masculine_adjectives.csv and adjectives/de_masculine_adjectives.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:190: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  selected_masculine = pd.concat([selected_masculine, top_masculine])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:195: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  selected_feminine = pd.concat([selected_feminine, top_feminine])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:217: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'individua' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'Alternate Form'] = adjective[:-1] + 'a'\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:220: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'feministo' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'Alternate Form'] = adjective[:-1] + 'o'\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:190: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  selected_masculine = pd.concat([selected_masculine, top_masculine])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:195: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  selected_feminine = pd.concat([selected_feminine, top_feminine])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame saved as adjectives/de_feminine_adjectives.csv and adjectives/de_feminine_adjectives.parquet\n",
      "Copied adjectives/es_masculine_adjectives.csv to adjectives/stimulus_files/es_masculine_adjectives.csv\n",
      "Copied adjectives/es_feminine_adjectives.csv to adjectives/stimulus_files/es_feminine_adjectives.csv\n",
      "Copied adjectives/de_masculine_adjectives.csv to adjectives/stimulus_files/de_masculine_adjectives.csv\n",
      "Copied adjectives/de_feminine_adjectives.csv to adjectives/stimulus_files/de_feminine_adjectives.csv\n",
      "Processing language: Spanish\n",
      "Conducting control tests for Spanish\n",
      "Creating control test dataframe for language: es\n",
      "Processing nouns for gender: feminine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing nouns for gender: masculine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing masculine adjectives\n",
      "Calculating similarities for masculine adjectives with genders\n",
      "Calculating similarities for masculine adjectives with determiners\n",
      "Processing feminine adjectives\n",
      "Calculating similarities for feminine adjectives with genders\n",
      "Calculating similarities for feminine adjectives with determiners\n",
      "Columns in control_data DataFrame: ['LANGUAGE', 'REFERENCE GROUP', 'REFERENCE ASSOCIATION', 'REFERENCE WORD', 'TARGET GROUP', 'TARGET WORD', 'COSINE SIMILARITY']\n",
      "Control test dataframe created for language: es, Rows: 1300\n",
      "Control test dataframe created for language: es, Rows: 1300\n",
      "Plotting: Spanish: Nouns - Genders\n",
      "Plot saved: plots/es/es_nouns-genders_box.png\n",
      "Writing statistics to report: reports/es_control_report.txt\n",
      "Report written: reports/es_control_report.txt\n",
      "Plotting: Spanish: Nouns - Determiners\n",
      "Plot saved: plots/es/es_nouns-determiners_box.png\n",
      "Writing statistics to report: reports/es_control_report.txt\n",
      "Report written: reports/es_control_report.txt\n",
      "Plotting: Spanish: Adjectives - Genders\n",
      "Plot saved: plots/es/es_adjectives-genders_box.png\n",
      "Writing statistics to report: reports/es_control_report.txt\n",
      "Report written: reports/es_control_report.txt\n",
      "Plotting: Spanish: Adjectives - Determiners\n",
      "Plot saved: plots/es/es_adjectives-determiners_box.png\n",
      "Writing statistics to report: reports/es_control_report.txt\n",
      "Report written: reports/es_control_report.txt\n",
      "Creating control test dataframe for language: es\n",
      "Processing nouns for gender: feminine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing nouns for gender: masculine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing masculine adjectives\n",
      "Calculating similarities for masculine adjectives with genders\n",
      "Calculating similarities for masculine adjectives with determiners\n",
      "Processing feminine adjectives\n",
      "Calculating similarities for feminine adjectives with genders\n",
      "Calculating similarities for feminine adjectives with determiners\n",
      "Columns in control_data DataFrame: ['LANGUAGE', 'REFERENCE GROUP', 'REFERENCE ASSOCIATION', 'REFERENCE WORD', 'TARGET GROUP', 'TARGET WORD', 'COSINE SIMILARITY']\n",
      "Control test dataframe created for language: es, Rows: 1300\n",
      "Control test dataframe created for language: es, Rows: 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating control test dataframe for language: es\n",
      "Processing nouns for gender: feminine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing nouns for gender: masculine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing masculine adjectives\n",
      "Calculating similarities for masculine adjectives with genders\n",
      "Calculating similarities for masculine adjectives with determiners\n",
      "Processing feminine adjectives\n",
      "Calculating similarities for feminine adjectives with genders\n",
      "Calculating similarities for feminine adjectives with determiners\n",
      "Columns in control_data DataFrame: ['LANGUAGE', 'REFERENCE GROUP', 'REFERENCE ASSOCIATION', 'REFERENCE WORD', 'TARGET GROUP', 'TARGET WORD', 'COSINE SIMILARITY']\n",
      "Control test dataframe created for language: es, Rows: 1300\n",
      "Control test dataframe created for language: es, Rows: 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting experimental tests for Spanish\n",
      "Creating experimental test dataframe for language: es\n",
      "Experimental test dataframe created for language: es, Rows: 178\n",
      "Plotting: Spanish: Nouns - Adjectives\n",
      "Plot saved: plots/es/es_nouns-adjectives_box.png\n",
      "Writing statistics to report: reports/es_experimental_report.txt\n",
      "Report written: reports/es_experimental_report.txt\n",
      "Processing language: German\n",
      "Conducting control tests for German\n",
      "Creating control test dataframe for language: de\n",
      "Processing nouns for gender: masculine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing nouns for gender: feminine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing masculine adjectives\n",
      "Calculating similarities for masculine adjectives with genders\n",
      "Calculating similarities for masculine adjectives with determiners\n",
      "Processing feminine adjectives\n",
      "Calculating similarities for feminine adjectives with genders\n",
      "Calculating similarities for feminine adjectives with determiners\n",
      "Columns in control_data DataFrame: ['LANGUAGE', 'REFERENCE GROUP', 'REFERENCE ASSOCIATION', 'REFERENCE WORD', 'TARGET GROUP', 'TARGET WORD', 'COSINE SIMILARITY']\n",
      "Control test dataframe created for language: de, Rows: 1145\n",
      "Control test dataframe created for language: de, Rows: 1145\n",
      "Plotting: German: Nouns - Genders\n",
      "Plot saved: plots/de/de_nouns-genders_box.png\n",
      "Writing statistics to report: reports/de_control_report.txt\n",
      "Report written: reports/de_control_report.txt\n",
      "Plotting: German: Nouns - Determiners\n",
      "Plot saved: plots/de/de_nouns-determiners_box.png\n",
      "Writing statistics to report: reports/de_control_report.txt\n",
      "Report written: reports/de_control_report.txt\n",
      "Plotting: German: Adjectives - Genders\n",
      "Plot saved: plots/de/de_adjectives-genders_box.png\n",
      "Writing statistics to report: reports/de_control_report.txt\n",
      "Report written: reports/de_control_report.txt\n",
      "Plotting: German: Adjectives - Determiners\n",
      "Plot saved: plots/de/de_adjectives-determiners_box.png\n",
      "Writing statistics to report: reports/de_control_report.txt\n",
      "Report written: reports/de_control_report.txt\n",
      "Creating control test dataframe for language: de\n",
      "Processing nouns for gender: masculine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing nouns for gender: feminine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing masculine adjectives\n",
      "Calculating similarities for masculine adjectives with genders\n",
      "Calculating similarities for masculine adjectives with determiners\n",
      "Processing feminine adjectives\n",
      "Calculating similarities for feminine adjectives with genders\n",
      "Calculating similarities for feminine adjectives with determiners\n",
      "Columns in control_data DataFrame: ['LANGUAGE', 'REFERENCE GROUP', 'REFERENCE ASSOCIATION', 'REFERENCE WORD', 'TARGET GROUP', 'TARGET WORD', 'COSINE SIMILARITY']\n",
      "Control test dataframe created for language: de, Rows: 1145\n",
      "Control test dataframe created for language: de, Rows: 1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating control test dataframe for language: de\n",
      "Processing nouns for gender: masculine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing nouns for gender: feminine\n",
      "Calculating similarities for nouns with genders\n",
      "Calculating similarities for nouns with determiners\n",
      "Processing masculine adjectives\n",
      "Calculating similarities for masculine adjectives with genders\n",
      "Calculating similarities for masculine adjectives with determiners\n",
      "Processing feminine adjectives\n",
      "Calculating similarities for feminine adjectives with genders\n",
      "Calculating similarities for feminine adjectives with determiners\n",
      "Columns in control_data DataFrame: ['LANGUAGE', 'REFERENCE GROUP', 'REFERENCE ASSOCIATION', 'REFERENCE WORD', 'TARGET GROUP', 'TARGET WORD', 'COSINE SIMILARITY']\n",
      "Control test dataframe created for language: de, Rows: 1145\n",
      "Control test dataframe created for language: de, Rows: 1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n",
      "/var/folders/0b/rqv03bjn7rv2x6q_bv2828fh0000gn/T/ipykernel_22842/407211372.py:402: UserWarning: The palette list has more values (2) than needed (1), which may not be intended.\n",
      "  sns.scatterplot(data=plot_data, x='Similarity to Gender Word', y='Avg Similarity to Gender Nouns', hue='Association', palette=['blue', 'orange'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting experimental tests for German\n",
      "Creating experimental test dataframe for language: de\n",
      "Experimental test dataframe created for language: de, Rows: 178\n",
      "Plotting: German: Nouns - Adjectives\n",
      "Plot saved: plots/de/de_nouns-adjectives_box.png\n",
      "Writing statistics to report: reports/de_experimental_report.txt\n",
      "Report written: reports/de_experimental_report.txt\n",
      "Finished processing, plotting, and generating reports for tests.\n"
     ]
    }
   ],
   "source": [
    "# sns.set_theme()\n",
    "\n",
    "run(\n",
    "    procedures={\n",
    "        'load_models':False,\n",
    "        \n",
    "        'crawl_wiktionary_nouns':False,\n",
    "        'crawl_wiktionary_adjectives':False,\n",
    "\n",
    "        'calculate_adjective_similarities':False,\n",
    "\n",
    "        'select_top_adjectives':True,\n",
    "\n",
    "        'remove_adjective_duplicates':True,\n",
    "        'adjective_definition_review':False,\n",
    "        'remove_unwanted_adjectives':True,\n",
    "\n",
    "        'create_stimulus_files':True,\n",
    "\n",
    "        'conduct_control_tests':True,\n",
    "        'conduct_experimental_tests':True,\n",
    "    },\n",
    "    models=models,\n",
    "    load_method='normal',\n",
    "    # normal, facebook\n",
    "    nouns_file='nouns.csv',\n",
    "    top_n_adjectives=100,\n",
    "    adjective_gender_association_method='cosine_similarity',\n",
    "    remove_adjectives_with_markers = [\"dated\", \"archaic\", \"dialectal\", \"rare\", \"ordinal number\", \"obsolete\", \"offensive\"],\n",
    "    # semantic differential\n",
    "    # to add: projection, simple selection (cossim(reference, target)), exclusive selection (cossim(reference, (target1 - target2)))\n",
    "    plot_type='box',\n",
    "    # box, strip\n",
    "    # to add: violin, swarm\n",
    "    # to fix: boxplots respond to order, hue_order parameters w/ boxprops error; for some plots are of irregular order\n",
    "    use_groupby=True,\n",
    "    # for experimental tests, group adjectives for a given noun into one average cosine similarity, so instead of n(nouns)*n(adjectives) data points, you only have n(nouns) datapoints. best for strip plots to see individual points.\n",
    "    semantic_differential_vectors='gender1-gender2',\n",
    "    # gender1-gender2, gender-person\n",
    "    unallowed_words=['lesb', 'debonair', 'vestal', 'sunamita', 'negrid', 'Brummagem', 'follable', 'untervÃ¶gelt', 'schasaugert', 'Emeser', 'fÃ¼nfhundertste', 'Poppersch', 'SchlÃ¤nger', 'RÃ¶mer', 'Latina', 'titless', 'pussy', 'foine', 'mosuo', 'fÃ¡ustico', 'indio', 'rixig', 'hiborio', 'abgeschmack', 'kaki', 'klaviform', 'TK', 'antimalthusianisch', 'Danubian', 'eblaitisch', 'elfminÃ¼tig', 'Fregesch', 'jakobinisch', 'Malthusianisch', 'meiÃenisch', 'neunminÃ¼tig', 'rahn', 'vierzigminÃ¼tig', 'zwÃ¶lfminÃ¼tig', 'Afro-Latina', 'Dianic', 'Filipina', 'lady-like', 'MAAB', 'menstruate', 'obstetrical', 'Quebecoise', 'Rubenesque', 'woman-centric', 'vinny', 'twinky', 'Welshy', 'turrible', 'mick', 'fooking', 'particuler', 'legendry', 'awsome', 'roy', 'neo-Hegelian', 'phun', 'niiice', 'Democritean', 'Hegelian', 'Rothbardian', 'gent', 'afrodescendiente', 'axumita', 'curvi', 'delhita', 'feminazi', 'madrense', 'mizrajÃ­', 'oseta', 'postparto', 'sefaradita', 'sefardÃ­', 'sefardita', 'transgenerista', 'fuckin', 'hanbalitisch', 'antimalthusianisch', 'Malthusianisch', 'antimalthusianisch', 'malthusisch','gustiÃ¶s', 'hanbalitisch','handgehoben','scheiÃ', 'sturm', 'terrisch','Madonna-like','smoove', 'tuff','hench','insano', 'mofo', 'cutty', 'piff', 'jake', 'propa', 'mank','LGBT','papaya', 'child-bearing', 'plus-sized', 'post-partum', 'vulval', 'ben', 'unpossible', 'antifeminist', 'LGTB', 'LGTBI', 'babylonisch', 'erzgebirgisch', 'hinreissend', 'niedersorbisch', 'Sanct', 'sasanidisch', 'saudisch', 'altniederlÃ¤ndisch', 'bohrsch', 'britannisch', 'danubisch', 'dreiundvierzigminÃ¼tig', 'drittelzahlig', 'etatmÃ¤ssig', 'fÃ¼nfundzwanzigminÃ¼tig', 'fÃ¼nfunddreiÃigminÃ¼tig', 'fÃ¼nfminÃ¼tig', 'Hitlersch', 'koblenzisch', 'Luthersch', 'sechzigminÃ¼tig', 'sÃ¼datlantisch', 'Cesarean', 'prochoice', 'almight', 'cock-sure', 'cooool', 'nooby', 'peart', 'phantastic', 'Smithian', 'barakaldarra', 'bartorosellista', 'cefeida', 'chilota', 'dailamita', 'estambulita', 'kÃ¡bila', 'mazahua', 'ondarrutarra', 'ranjana', 'helle', 'zirkummediterran', 'sÃ¼datlantisch', 'preggers', 'vajazzled', 'shite', 'steezy', 'tinhorn', 'widdly', 'afrotropical', 'apollardado', 'mijita', 'ladilla', 'gray-haired', 'heavy-set', 'middleaged', 'Jew,' 'moustached', 'African-American', 'childbearing', 'Filipina', 'Madonna-like', 'newly-wed', 'Shunamite', 'Syrophoenician', 'teen-age', 'teen-aged', 'transgendered', 'grown-ass', 'mustached', 'Caucasian', 'biracial', 'mixed-race', 'thirties', 'forties', 'clean-shaved', 'moustachioed', 'dark-skinned', 'teenaged', 'mustachioed', 'ape', 'Afroestadounidense', 'Birracial', 'IndÃ­gena', 'sexi', 'Extraconyugal', 'Israelita', 'untrew', 'cristiano', 'jÃ³ven', 'afroestadounidense', 'birracial', 'Emesener', 'baktrisch', 'israelita', 'â¥-lich', 'vierzigmonatig', 'wÃ¤hrschaft', 'wolgadeutsch', 'amisch', 'dreiundfÃ¼nfzigjÃ¤hrig', 'kraftwerkisch', 'malisch', 'Palmyrer', 'Portaner' ,'achtundvierzigmonatig', 'padre', 'hypoÃ¤olisch', 'schwatt', 'sechsunddreiÃigmonatig', 'israelita', 'dreiÃigmonatig', 'einunddreiÃigeckig', 'schwul', 'mannmÃ¤nnlich'],\n",
    "    allowed_words=['rascal', 'transexual'],\n",
    "    font_size=14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the CSV file: 267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with your actual file name\n",
    "df = pd.read_csv('balanced_nouns.csv')\n",
    "\n",
    "# Getting the number of rows\n",
    "number_of_rows = len(df)\n",
    "print(\"Number of rows in the CSV file:\", number_of_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "Top pairs for de_feminine_adjectives.csv:\n",
      "#################################\n",
      "transsexuell, intersexuell - Cosine Similarity: 0.7170\n",
      "krebskrank, sterbenskrank - Cosine Similarity: 0.6682\n",
      "#################################\n",
      "Top pairs for es_masculine_adjectives.csv:\n",
      "#################################\n",
      "fornido, corpulento - Cosine Similarity: 0.8345\n",
      "adinerado, acaudalado - Cosine Similarity: 0.8102\n",
      "#################################\n",
      "Top pairs for es_feminine_adjectives.csv:\n",
      "#################################\n",
      "casado, divorciado - Cosine Similarity: 0.8197\n",
      "inmigrante, emigrante - Cosine Similarity: 0.8195\n",
      "#################################\n",
      "Top pairs for de_masculine_adjectives.csv:\n",
      "#################################\n",
      "betrunken, besoffen - Cosine Similarity: 0.8067\n",
      "alt, jung - Cosine Similarity: 0.7871\n",
      "#################################\n",
      "Top pairs for en_feminine_adjectives.csv:\n",
      "#################################\n",
      "marriageable, unmarriageable - Cosine Similarity: 0.8516\n",
      "womanly, womanless - Cosine Similarity: 0.7766\n",
      "#################################\n",
      "Top pairs for en_masculine_adjectives.csv:\n",
      "#################################\n",
      "true-hearted, gentle-hearted - Cosine Similarity: 0.8461\n",
      "septuagenarian, octogenarian - Cosine Similarity: 0.8429\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "def cossim(vec1, vec2):\n",
    "    \"\"\"Return cosine similarity between vec1 and vec2\"\"\"\n",
    "    dot_product = sum(a*b for a, b in zip(vec1, vec2))\n",
    "    magnitude1 = math.sqrt(sum([val**2 for val in vec1]))\n",
    "    magnitude2 = math.sqrt(sum([val**2 for val in vec2]))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def get(model, word):\n",
    "    \"\"\"Return word embedding for word as in model\"\"\"\n",
    "    return model.get_word_vector(word)\n",
    "\n",
    "def top_cosine_similarity_pairs(csv_file, model):\n",
    "    # Read adjectives from the \"Adjective\" column in the CSV\n",
    "    adjectives = []\n",
    "    with open(csv_file, newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if 'Adjective' in row:\n",
    "                adjectives.append(row['Adjective'])\n",
    "\n",
    "    # Calculate cosine similarity for all unique pairs\n",
    "    pairs = itertools.combinations(adjectives, 2)\n",
    "    similarity_scores = defaultdict(float)\n",
    "    for word1, word2 in pairs:\n",
    "        vec1 = get(model, word1)\n",
    "        vec2 = get(model, word2)\n",
    "        similarity = cossim(vec1, vec2)\n",
    "        similarity_scores[(word1, word2)] = similarity\n",
    "\n",
    "    # Sort pairs by similarity score\n",
    "    sorted_pairs = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 5%\n",
    "    top_5_percent_index = int(len(sorted_pairs) * 0.001)\n",
    "    top_pairs = sorted_pairs[:top_5_percent_index]\n",
    "\n",
    "    return top_pairs\n",
    "\n",
    "# Assuming top_cosine_similarity_pairs and other necessary functions are already defined\n",
    "# and your word embedding models are loaded into 'models'\n",
    "\n",
    "directory = \"adjectives/stimulus_files\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Select the appropriate model based on the filename\n",
    "        if \"de\" in filename:\n",
    "            model = models['de']\n",
    "        elif \"es\" in filename:\n",
    "            model = models['es']\n",
    "        elif \"en\" in filename:\n",
    "            model = models['en']\n",
    "        else:\n",
    "            print(f\"Language model for {filename} not found.\")\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        top_pairs = top_cosine_similarity_pairs(file_path, model)\n",
    "\n",
    "        # Print the top 5% pairs in a legible format\n",
    "        print('#################################')\n",
    "        print(f\"Top pairs for {filename}:\")\n",
    "        print('#################################')\n",
    "        for (word1, word2), similarity in top_pairs:\n",
    "            print(f\"{word1}, {word2} - Cosine Similarity: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: de_feminine_adjectives.csv\n",
      "Columns in DataFrame: ['Adjective', 'Language', 'masculine_similarity', 'feminine_similarity', 'exclusive_masculine_similarity', 'exclusive_feminine_similarity', 'neuter_similarity', 'depersonalized_masculine_similarity', 'depersonalized_feminine_similarity', 'masculine_score', 'feminine_score', 'Definition']\n",
      "Processing file: es_masculine_adjectives.csv\n",
      "Columns in DataFrame: ['Adjective', 'Language', 'masculine_similarity', 'feminine_similarity', 'exclusive_masculine_similarity', 'exclusive_feminine_similarity', 'neuter_similarity', 'depersonalized_masculine_similarity', 'depersonalized_feminine_similarity', 'masculine_score', 'feminine_score', 'Alternate Form', 'Definition']\n",
      "Processing file: es_feminine_adjectives.csv\n",
      "Columns in DataFrame: ['Adjective', 'Language', 'masculine_similarity', 'feminine_similarity', 'exclusive_masculine_similarity', 'exclusive_feminine_similarity', 'neuter_similarity', 'depersonalized_masculine_similarity', 'depersonalized_feminine_similarity', 'masculine_score', 'feminine_score', 'Alternate Form', 'Definition']\n",
      "Processing file: de_masculine_adjectives.csv\n",
      "Columns in DataFrame: ['Adjective', 'Language', 'masculine_similarity', 'feminine_similarity', 'exclusive_masculine_similarity', 'exclusive_feminine_similarity', 'neuter_similarity', 'depersonalized_masculine_similarity', 'depersonalized_feminine_similarity', 'masculine_score', 'feminine_score', 'Definition']\n",
      "Processing file: en_feminine_adjectives.csv\n",
      "Columns in DataFrame: ['Adjective', 'Language', 'masculine_similarity', 'feminine_similarity', 'exclusive_masculine_similarity', 'exclusive_feminine_similarity', 'neuter_similarity', 'depersonalized_masculine_similarity', 'depersonalized_feminine_similarity', 'masculine_score', 'feminine_score', 'Definition']\n",
      "Processing file: en_masculine_adjectives.csv\n",
      "Columns in DataFrame: ['Adjective', 'Language', 'masculine_similarity', 'feminine_similarity', 'exclusive_masculine_similarity', 'exclusive_feminine_similarity', 'neuter_similarity', 'depersonalized_masculine_similarity', 'depersonalized_feminine_similarity', 'masculine_score', 'feminine_score', 'Definition']\n",
      "Final row count for all files: 70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory = \"adjectives/stimulus_files\"\n",
    "\n",
    "\n",
    "# Function to find the minimum row count\n",
    "def find_min_row_count(files):\n",
    "    min_count = float('inf')\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "        min_count = min(min_count, len(df))\n",
    "    return min_count\n",
    "\n",
    "# List CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "# Find the minimum row count\n",
    "min_row_count = find_min_row_count(csv_files)\n",
    "\n",
    "# Truncate files based on criteria\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(directory, file))\n",
    "    print(f\"Processing file: {file}\")\n",
    "    print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "    if 'masculine' in file.lower() and 'masculine_score' in df.columns:\n",
    "        df = df.nsmallest(min_row_count, 'masculine_score')\n",
    "    elif 'feminine' in file.lower() and 'feminine_Score' in df.columns:\n",
    "        df = df.nsmallest(min_row_count, 'feminine_Score')\n",
    "    \n",
    "    # Save the truncated file\n",
    "    df.to_csv(os.path.join(directory, file), index=False)\n",
    "\n",
    "# Print the final row count\n",
    "print(f\"Final row count for all files: {min_row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to adjectives/random_order/es_masculine_adjectives_random_order.csv\n",
      "Output saved to adjectives/random_order/es_feminine_adjectives_random_order.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_feminine(adj):\n",
    "    if adj.endswith('o'):\n",
    "        return adj[:-1] + 'a'\n",
    "    elif adj.endswith('or'):\n",
    "        return adj + 'a'\n",
    "    elif adj.endswith('Ã¡n') or adj.endswith('Ã³n') or adj.endswith('Ã­n'):\n",
    "        return adj[:-2] + 'ana'\n",
    "    # Add more rules as necessary\n",
    "    return adj  # Return as-is for adjectives that don't change\n",
    "\n",
    "def convert_to_masculine(adj):\n",
    "    if adj.endswith('a') and not adj.endswith('ista'):\n",
    "        return adj[:-1] + 'o'\n",
    "    # Add more rules as necessary\n",
    "    return adj  # Return as-is for adjectives that don't change\n",
    "\n",
    "def process_adjectives(file_path, gender):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Check if 'Adjective' column exists\n",
    "    if 'Adjective' not in df.columns:\n",
    "        raise ValueError(\"CSV file does not have an 'Adjective' column.\")\n",
    "\n",
    "    # Apply the conversion based on gender\n",
    "    if gender == 'masculine':\n",
    "        df['Masculine'] = df['Adjective']\n",
    "        df['Feminine'] = df['Adjective'].apply(convert_to_feminine)\n",
    "    elif gender == 'feminine':\n",
    "        df['Masculine'] = df['Adjective'].apply(convert_to_masculine)\n",
    "        df['Feminine'] = df['Adjective']\n",
    "\n",
    "    # Determine output file name\n",
    "    output_file = file_path.replace('stimulus_files', 'random_order').replace('.csv', '_random_order.csv')\n",
    "\n",
    "    # Write to a new CSV file\n",
    "    df[['Masculine', 'Feminine']].to_csv(output_file, index=False)\n",
    "    print(f\"Output saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "process_adjectives(\"adjectives/stimulus_files/es_masculine_adjectives.csv\", \"masculine\")\n",
    "process_adjectives(\"adjectives/stimulus_files/es_feminine_adjectives.csv\", \"feminine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each 'ASSOCIATION/GRAMMATICAL GENDER' group:\n",
      "ASSOCIATION/GRAMMATICAL GENDER\n",
      "feminine     89\n",
      "masculine    89\n",
      "neuter       89\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_adjectives_by_group(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Group by 'ASSOCIATION/GRAMMATICAL GENDER' and count\n",
    "    group_counts = df.groupby('ASSOCIATION/GRAMMATICAL GENDER').size()\n",
    "\n",
    "    # Print the count for each group\n",
    "    print(\"Counts for each 'ASSOCIATION/GRAMMATICAL GENDER' group:\")\n",
    "    print(group_counts)\n",
    "\n",
    "# Example usage\n",
    "count_adjectives_by_group('nouns.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each 'ASSOCIATION/GRAMMATICAL GENDER' group within each language:\n",
      "LANGUAGE  ASSOCIATION/GRAMMATICAL GENDER\n",
      "de        feminine                          40\n",
      "          masculine                         40\n",
      "en        neuter                            80\n",
      "es        feminine                          40\n",
      "          masculine                         40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_adjectives_by_language_and_gender(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Group by 'LANGUAGE' and 'ASSOCIATION/GRAMMATICAL GENDER' and count\n",
    "    group_counts = df.groupby(['LANGUAGE', 'ASSOCIATION/GRAMMATICAL GENDER']).size()\n",
    "\n",
    "    # Print the count for each group within each language\n",
    "    print(\"Counts for each 'ASSOCIATION/GRAMMATICAL GENDER' group within each language:\")\n",
    "    print(group_counts)\n",
    "\n",
    "# Example usage\n",
    "count_adjectives_by_language_and_gender('nouns.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to equalized_adjectives.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def equalize_adjectives(file_path, protected_translations):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Group by 'LANGUAGE' and 'ASSOCIATION/GRAMMATICAL GENDER' and count\n",
    "    group_counts = df.groupby(['LANGUAGE', 'ASSOCIATION/GRAMMATICAL GENDER']).size()\n",
    "\n",
    "    # Exclude English and find the minimum count\n",
    "    target_count = group_counts.drop('en').min()\n",
    "\n",
    "    # Filter and equalize each group\n",
    "    result_df = pd.DataFrame()\n",
    "    for (language, gender), count in group_counts.items():\n",
    "        if language == 'en':  # Skip English\n",
    "            result_df = result_df._append(df[(df['LANGUAGE'] == language) & \n",
    "                                            (df['ASSOCIATION/GRAMMATICAL GENDER'] == gender)])\n",
    "            continue\n",
    "\n",
    "        # Filter the group\n",
    "        group_df = df[(df['LANGUAGE'] == language) & \n",
    "                      (df['ASSOCIATION/GRAMMATICAL GENDER'] == gender)]\n",
    "\n",
    "        # Separate protected and non-protected items\n",
    "        protected_df = group_df[group_df['TRANSLATION'].isin(protected_translations)]\n",
    "        non_protected_df = group_df[~group_df['TRANSLATION'].isin(protected_translations)]\n",
    "\n",
    "        # Reduce the non-protected items if necessary\n",
    "        if count > target_count:\n",
    "            num_to_keep = target_count - len(protected_df)\n",
    "            non_protected_df = non_protected_df.sample(n=num_to_keep)\n",
    "\n",
    "        # Append to the result DataFrame\n",
    "        result_df = result_df._append(protected_df, ignore_index=True)\n",
    "        result_df = result_df._append(non_protected_df, ignore_index=True)\n",
    "\n",
    "    # Write to a new CSV file\n",
    "    output_file = 'equalized_adjectives.csv'\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"Output saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "protected_translations = [\n",
    "    'toaster', 'moon', 'spoon', 'broom', 'whale', 'frog', \n",
    "    'clock', 'sun', 'fork', 'toothbrush', 'mouse', 'snail', 'cat'\n",
    "]\n",
    "equalize_adjectives('nouns.csv', protected_translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11c717a47cdf72da10bd78b4a5153590ad14cef22d0e68537b3d97dcd083fccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
